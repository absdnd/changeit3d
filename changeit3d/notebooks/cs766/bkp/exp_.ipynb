{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3kmtaJWsR4x"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPEbHjyoyuNg"
      },
      "source": [
        "### Google Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZA-kWZCr7xC"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# #drive.mount('/content/drive')\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-HAWmzSsOwV",
        "outputId": "e557a8bd-0067-4f3b-fe77-fd6dc433452f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'changeit3d'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 184 (delta 12), reused 184 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (184/184), 4.28 MiB | 7.46 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "/content/changeit3d\n",
            "Cloning into '/content/changeit3d/changeit3d/losses/ChamferDistancePytorch'...\n",
            "remote: Enumerating objects: 265, done.\u001b[K\n",
            "remote: Total 265 (delta 0), reused 0 (delta 0), pack-reused 265\u001b[K\n",
            "Receiving objects: 100% (265/265), 46.75 KiB | 5.19 MiB/s, done.\n",
            "Resolving deltas: 100% (163/163), done.\n",
            "Obtaining file:///content/changeit3d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (2.2.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (1.2.2)\n",
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (2023.8.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (3.8.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (4.66.2)\n",
            "Collecting jupyter (from changeit3d==0.1)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (1.11.4)\n",
            "Collecting plyfile (from changeit3d==0.1)\n",
            "  Downloading plyfile-1.0.3-py3-none-any.whl (23 kB)\n",
            "Collecting pandas<2.0.0 (from changeit3d==0.1)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (0.9.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (2.4.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (7.0.0)\n",
            "Collecting dill (from changeit3d==0.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (3.9.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from changeit3d==0.1) (0.13.1)\n",
            "Collecting symspellpy==6.5.2 (from changeit3d==0.1)\n",
            "  Downloading symspellpy-6.5.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0->changeit3d==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0->changeit3d==0.1) (2023.4)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (24.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]->changeit3d==0.1) (7.1.0)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->changeit3d==0.1) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect->changeit3d==0.1) (4.11.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->changeit3d==0.1) (6.5.5)\n",
            "Collecting qtconsole (from jupyter->changeit3d==0.1)\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->changeit3d==0.1) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->changeit3d==0.1) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->changeit3d==0.1) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->changeit3d==0.1) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->changeit3d==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->changeit3d==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->changeit3d==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->changeit3d==0.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->changeit3d==0.1) (3.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->changeit3d==0.1) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->changeit3d==0.1) (2023.12.25)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->changeit3d==0.1) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->changeit3d==0.1) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->changeit3d==0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->changeit3d==0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->changeit3d==0.1) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->changeit3d==0.1)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->changeit3d==0.1) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->changeit3d==0.1)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]->changeit3d==0.1) (3.18.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask[dataframe]->changeit3d==0.1) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->changeit3d==0.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->changeit3d==0.1) (2.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0->changeit3d==0.1) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->changeit3d==0.1) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->changeit3d==0.1) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->changeit3d==0.1) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->changeit3d==0.1) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->changeit3d==0.1) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->changeit3d==0.1) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->changeit3d==0.1) (3.0.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->changeit3d==0.1) (2.1.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->changeit3d==0.1) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->changeit3d==0.1) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->changeit3d==0.1) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->changeit3d==0.1) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->changeit3d==0.1) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->changeit3d==0.1) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->changeit3d==0.1) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->changeit3d==0.1) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->changeit3d==0.1) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->changeit3d==0.1) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->changeit3d==0.1)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->changeit3d==0.1) (1.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->changeit3d==0.1) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->changeit3d==0.1) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->changeit3d==0.1) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->changeit3d==0.1) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->changeit3d==0.1) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->changeit3d==0.1) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter->changeit3d==0.1) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->changeit3d==0.1) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->changeit3d==0.1) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->changeit3d==0.1) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->changeit3d==0.1) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->changeit3d==0.1) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->changeit3d==0.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->changeit3d==0.1) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->changeit3d==0.1) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->changeit3d==0.1) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->changeit3d==0.1) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->changeit3d==0.1) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->changeit3d==0.1) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->changeit3d==0.1) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->changeit3d==0.1) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->changeit3d==0.1) (2.22)\n",
            "Installing collected packages: symspellpy, qtpy, plyfile, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, dill, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, qtconsole, jupyter, changeit3d\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Running setup.py develop for changeit3d\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed changeit3d-0.1 dill-0.3.8 jedi-0.19.1 jupyter-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 plyfile-1.0.3 qtconsole-5.5.1 qtpy-2.4.1 symspellpy-6.5.2\n",
            "Collecting Ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Ninja\n",
            "Successfully installed Ninja-1.11.1.1\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/optas/changeit3d\n",
        "# %cd changeit3d\n",
        "# !git submodule add https://github.com/ThibaultGROUEIX/ChamferDistancePytorch changeit3d/losses/ChamferDistancePytorch\n",
        "# !pip install -e .\n",
        "# !pip install Ninja\n",
        "# !pip install wandb\n",
        "# import sys\n",
        "# sys.path.append('/content/drive/Shareddrives/CS766/changeit3d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNMTennNywD1",
        "outputId": "e5122eed-0698-472f-e143-d8a1a6135be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hspt9a34sThv",
        "outputId": "eb6a87df-2274-4918-b33c-27d971b19f26"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel died. Error: /home/aharish2/miniconda3/bin/python: No module named ipykernel_launcher... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "from functools import partial\n",
        "\n",
        "from changeit3d.in_out.changeit3d_net import prepare_input_data\n",
        "from changeit3d.in_out.language_contrastive_dataset import LanguageContrastiveDataset\n",
        "from changeit3d.in_out.pointcloud import pc_loader_from_npz, uniform_subsample\n",
        "from changeit3d.in_out.basics import pickle_data\n",
        "from changeit3d.in_out.basics import create_logger\n",
        "from changeit3d.in_out.arguments import parse_evaluate_changeit3d_arguments\n",
        "\n",
        "from changeit3d.utils.basics import parallel_apply\n",
        "from changeit3d.models.model_descriptions import load_pretrained_changeit3d_net\n",
        "from changeit3d.models.model_descriptions import load_pretrained_pc_ae\n",
        "\n",
        "from changeit3d.evaluation.auxiliary import pc_ae_transform_point_clouds, sgf_transform_point_clouds\n",
        "from changeit3d.external_tools.sgf.loader import initialize_and_load_sgf\n",
        "from changeit3d.utils.visualization import visualize_point_clouds_3d_v2, plot_3d_point_cloud\n",
        "from changeit3d.in_out.arguments import parse_evaluate_changeit3d_arguments\n",
        "from changeit3d.in_out.changeit3d_net import prepare_input_data\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyD9QHOEsh16"
      },
      "source": [
        "### Specify Data Paths to Utilize: This is specified using the excel `shapetalk_preprocessed_public_version_0.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5D8Xd2PSEuL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/Shareddrives/CS766/changeit3d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObKDUBq_sg47",
        "outputId": "4fb44b2f-c468-4675-a8c8-d1b126638531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Input arguments:\n",
            "\n",
            "\n",
            "{'batch_size': 1024,\n",
            " 'clean_train_val_data': False,\n",
            " 'compute_fpd': True,\n",
            " 'evaluate_retrieval_version': False,\n",
            " 'experiment_tag': None,\n",
            " 'gpu_id': 0,\n",
            " 'latent_codes_file': '../drive/Shareddrives/CS766/pretrained_models/data/pretrained/shape_latents/pcae_latent_codes.pkl',\n",
            " 'log_dir': './logs',\n",
            " 'n_sample_points': 2048,\n",
            " 'num_workers': 10,\n",
            " 'pretrained_changeit3d': '../drive/Shareddrives/CS766/pretrained_models/data/pretrained/changers/pcae_based/all_shapetalk_classes/decoupling_mag_direction/idpen_0.05_sc_True//best_model.pt',\n",
            " 'pretrained_oracle_listener': '../drive/Shareddrives/CS766/pretrained_models/data/pretrained/listeners/oracle_listener/all_shapetalk_classes/rs_2023/listener_dgcnn_based/ablation1/best_model.pkl',\n",
            " 'pretrained_shape_classifier': '../drive/Shareddrives/CS766/pretrained_models/data/pretrained/pc_classifiers/rs_2022/all_shapetalk_classes/best_model.pkl',\n",
            " 'pretrained_shape_generator': '../drive/Shareddrives/CS766/pretrained_models/data/pretrained/pc_autoencoders/pointnet/rs_2022/points_4096/all_classes/scaled_to_align_rendering/08-07-2022-22-23-42/best_model.pt',\n",
            " 'random_seed': 2022,\n",
            " 'restrict_shape_class': ['chair', 'table', 'lamp'],\n",
            " 'save_reconstructions': False,\n",
            " 'shape_generator_type': 'pcae',\n",
            " 'shape_part_classifiers_top_dir': '../drive/Shareddrives/CS766/pretrained_models/data/pretrained/part_predictors/shapenet_core_based',\n",
            " 'shape_talk_file': '../drive/Shareddrives/CS766/shapetalk_dataset/shapetalk/language/shapetalk_preprocessed_public_version_0.csv',\n",
            " 'sub_sample_dataset': None,\n",
            " 'top_pc_dir': '../drive/Shareddrives/CS766/shapetalk_dataset/shapetalk/point_clouds/scaled_to_align_rendering',\n",
            " 'use_timestamp': False,\n",
            " 'vocab_file': '../drive/Shareddrives/CS766/shapetalk_dataset/shapetalk/language/vocabulary.pkl'}\n"
          ]
        }
      ],
      "source": [
        "##\n",
        "## Manually specify the underlying files using our pretrained nets or yours\n",
        "## COMPLETE - UPDATED WITH MY FILE PATHS\n",
        "##\n",
        "\n",
        "#shape_generator_type = \"sgf\"\n",
        "shape_generator_type = \"pcae\"\n",
        "#shape_generator_type = \"resnet101\"\n",
        "\n",
        "top_data_dir = '../drive/Shareddrives/CS766/shapetalk_dataset'\n",
        "top_train_dir = '../drive/Shareddrives/CS766/pretrained_models/data'\n",
        "shape_talk_file = f'{top_data_dir}/shapetalk/language/shapetalk_preprocessed_public_version_0.csv'\n",
        "vocab_file = f'{top_data_dir}/shapetalk/language/vocabulary.pkl'\n",
        "top_pc_dir = f'{top_data_dir}/shapetalk/point_clouds/scaled_to_align_rendering'\n",
        "pretrained_oracle_listener = f'{top_train_dir}/pretrained/listeners/oracle_listener/all_shapetalk_classes/rs_2023/listener_dgcnn_based/ablation1/best_model.pkl'\n",
        "pretrained_shape_classifier =  f'{top_train_dir}/pretrained/pc_classifiers/rs_2022/all_shapetalk_classes/best_model.pkl'\n",
        "shape_part_classifiers_top_dir = f'{top_train_dir}/pretrained/part_predictors/shapenet_core_based'\n",
        "latent_codes_file = f'{top_train_dir}/pretrained/shape_latents/{shape_generator_type}_latent_codes.pkl'\n",
        "\n",
        "\n",
        "\n",
        "### Loading in Pretrained Shapetalk PC-AE.\n",
        "if shape_generator_type == \"pcae\":\n",
        "    pretrained_shape_generator = f'{top_train_dir}/pretrained/pc_autoencoders/pointnet/rs_2022/points_4096/all_classes/scaled_to_align_rendering/08-07-2022-22-23-42/best_model.pt'\n",
        "    ## selected PC-AE ablation:\n",
        "    selected_ablation = 'decoupling_mag_direction/idpen_0.05_sc_True/' # decoupled and with self-contrast=True\n",
        "\n",
        "### SGF-AE based ShapeTalk dataset pre-trained.\n",
        "if shape_generator_type == \"sgf\":\n",
        "    selected_ablation = 'decoupling_mag_direction/idpen_0.05_sc_True/'\n",
        "    sub_sample_dataset = '100' # just evaluate over 100 randomly selected test shapes\n",
        "\n",
        "# Pre-trained ChangeIT3D Arguments\n",
        "pretrained_changeit3d = f'{top_train_dir}/pretrained/changers/{shape_generator_type}_based/all_shapetalk_classes/{selected_ablation}/best_model.pt'\n",
        "\n",
        "notebook_arguments = []\n",
        "\n",
        "notebook_arguments.extend(['-shape_talk_file', shape_talk_file])\n",
        "notebook_arguments.extend(['-latent_codes_file', latent_codes_file])\n",
        "notebook_arguments.extend(['-vocab_file', vocab_file])\n",
        "notebook_arguments.extend(['-pretrained_changeit3d', pretrained_changeit3d])\n",
        "notebook_arguments.extend(['-top_pc_dir', top_pc_dir])\n",
        "notebook_arguments.extend(['--shape_generator_type', shape_generator_type])\n",
        "notebook_arguments.extend(['--pretrained_oracle_listener', pretrained_oracle_listener])\n",
        "notebook_arguments.extend(['--pretrained_shape_classifier', pretrained_shape_classifier])\n",
        "notebook_arguments.extend(['--shape_part_classifiers_top_dir', shape_part_classifiers_top_dir])\n",
        "\n",
        "if 'pretrained_shape_generator' in  locals():\n",
        "    notebook_arguments.extend(['--pretrained_shape_generator', pretrained_shape_generator])\n",
        "\n",
        "if 'sub_sample_dataset' in  locals():\n",
        "    notebook_arguments.extend(['--sub_sample_dataset', sub_sample_dataset])\n",
        "\n",
        "\n",
        "# Arguments being parsed here. #\n",
        "args = parse_evaluate_changeit3d_arguments(notebook_arguments)\n",
        "logger = create_logger(args.log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATse34qIzIEc"
      },
      "source": [
        "### Dataloader for Custom Shapes\n",
        "\n",
        "*   Pass in same arguments as the normal `LanguageContrastiveDataset`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXflrqypwsEC"
      },
      "outputs": [],
      "source": [
        "# Use this for custom shapes\n",
        "class ShapeTalkCustomShapeDataset(Dataset):\n",
        "  def __init__(self, data_frame, to_stimulus_func=None, shuffle_items=False, n_distractors=2,\n",
        "                 shape_to_latent_code=None, encoder=None, base_data_dir = None, target_base_dir = None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_frame:\n",
        "            to_stimulus_func:\n",
        "            shuffle_items:\n",
        "            n_distractors:\n",
        "            shape_to_latent_code:\n",
        "        \"\"\"\n",
        "        super(ShapeTalkCustomShapeDataset, self).__init__()\n",
        "        self.df = data_frame\n",
        "        self.shuffle_items = shuffle_items\n",
        "        self.n_distractors = n_distractors\n",
        "        self.to_stimulus_func = to_stimulus_func\n",
        "        self.shape_to_latent_code = shape_to_latent_code\n",
        "        self.encoder = encoder\n",
        "        self.base_data_dir = base_data_dir\n",
        "        self.target_base_dir = target_base_dir\n",
        "\n",
        "        # self.remove_missing_data()\n",
        "\n",
        "  # Remove Missing Data from the point clouds #\n",
        "  def remove_missing_data(self):\n",
        "      if self.base_data_dir is None or self.to_stimulus_func is not None:\n",
        "          return\n",
        "      bad_data_idxs = []\n",
        "\n",
        "      # Working with a data frame #\n",
        "      for idx in range(len(self.df)):\n",
        "          item_ids = []\n",
        "          row = self.df.iloc[idx]\n",
        "          for i in range(1, self.n_distractors + 1):\n",
        "              item_ids.append(row[f'distractor_{i}'])\n",
        "          item_ids.append(row['target'])  #\n",
        "\n",
        "          # Item Ids #\n",
        "          for x in item_ids:\n",
        "            item_class, item_dataset, noise_value, item_code = x.split(\"/\")\n",
        "            test_pc_path = self.base_data_dir + \"/\" + item_class + \"/\" + item_dataset + \"/\" + noise_value + \"/\" + item_code\n",
        "            if not os.path.exists(test_pc_path):\n",
        "                bad_data_idxs.append(idx)\n",
        "                break\n",
        "\n",
        "      print(\"Number of Bad Indexes\", len(bad_data_idxs))\n",
        "      self.df.drop(bad_data_idxs)\n",
        "      print(\"Removed Missing Data, Dataset has\", len(self.df), \"elements\")\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      row = self.df.iloc[index]\n",
        "      tokens = row['tokens_encoded']\n",
        "      tokens = np.array(tokens).T  # todo do via collate.\n",
        "\n",
        "      item_ids = []\n",
        "      for i in range(1, self.n_distractors + 1):\n",
        "          item_ids.append(row[f'distractor_{i}'])\n",
        "\n",
        "      item_ids.append(row['target'])  # now target is last.\n",
        "      item_ids = np.array(item_ids)\n",
        "      n_items = len(item_ids)\n",
        "      label = n_items - 1\n",
        "\n",
        "\n",
        "      if self.shuffle_items:\n",
        "          idx = np.arange(n_items)\n",
        "          np.random.shuffle(idx)\n",
        "          item_ids = item_ids[idx]\n",
        "          label = np.where(idx == label)[0][0]\n",
        "\n",
        "      res = dict()\n",
        "      res['tokens'] = tokens\n",
        "      res['label'] = label\n",
        "      res['index'] = index\n",
        "      res['pc_stimulus'] = index\n",
        "      # Loading all point clouds #\n",
        "      if self.to_stimulus_func is None:\n",
        "          res['pc_stimulus'] = []\n",
        "          for i, x in enumerate(item_ids):\n",
        "              if i == len(item_ids) - 1:\n",
        "                 item_class, item_dataset, item_code = x.split(\"/\")\n",
        "                 test_pc_path = self.target_base_dir + \"/\" + item_class + \"/\" + item_dataset + \"/\" + item_code + \".npz\"\n",
        "              else:\n",
        "                item_class, item_dataset, noise_value, item_code = x.split(\"/\")\n",
        "                test_pc_path = self.base_data_dir + \"/\" + item_class + \"/\" + item_dataset + \"/\" + noise_value + \"/\" + item_code\n",
        "\n",
        "              res['pc_stimulus'].append(np.load(test_pc_path)['pointcloud'])\n",
        "\n",
        "          res['pc_stimulus'] = np.stack(res['pc_stimulus'])\n",
        "          # print(res['pc_stimulus'].shape)\n",
        "          res['stimulus'] = index\n",
        "      else:\n",
        "          # print(\"Using Stimulus\", self.to_stimulus_func)\n",
        "          res['stimulus'] = []\n",
        "          for x in item_ids:\n",
        "              res['stimulus'].append(self.to_stimulus_func(x))\n",
        "          res['stimulus'] = np.stack(res['stimulus'])\n",
        "      return res\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feSd8BWV5K32"
      },
      "source": [
        "### Loading ChangeIt3D Net: ##\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nNv79yYSXnz",
        "outputId": "9a13c5bf-b1c6-44e2-b1b0-c2da26b927e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(shape_talk_file='../drive/Shareddrives/CS766/shapetalk_dataset/shapetalk/language/shapetalk_preprocessed_public_version_0.csv', vocab_file='../drive/Shareddrives/CS766/shapetalk_dataset/shapetalk/language/vocabulary.pkl', latent_codes_file='../drive/Shareddrives/CS766/pretrained_models/data/pretrained/shape_latents/pcae_latent_codes.pkl', pretrained_changeit3d='../drive/Shareddrives/CS766/pretrained_models/data/pretrained/changers/pcae_based/all_shapetalk_classes/decoupling_mag_direction/idpen_0.05_sc_True//best_model.pt', top_pc_dir='../drive/Shareddrives/CS766/shapetalk_dataset/shapetalk/point_clouds/scaled_to_align_rendering', restrict_shape_class=['chair', 'table', 'lamp'], pretrained_shape_classifier='../drive/Shareddrives/CS766/pretrained_models/data/pretrained/pc_classifiers/rs_2022/all_shapetalk_classes/best_model.pkl', compute_fpd=True, shape_part_classifiers_top_dir='../drive/Shareddrives/CS766/pretrained_models/data/pretrained/part_predictors/shapenet_core_based', pretrained_oracle_listener='../drive/Shareddrives/CS766/pretrained_models/data/pretrained/listeners/oracle_listener/all_shapetalk_classes/rs_2023/listener_dgcnn_based/ablation1/best_model.pkl', shape_generator_type='pcae', pretrained_shape_generator='../drive/Shareddrives/CS766/pretrained_models/data/pretrained/pc_autoencoders/pointnet/rs_2022/points_4096/all_classes/scaled_to_align_rendering/08-07-2022-22-23-42/best_model.pt', n_sample_points=2048, sub_sample_dataset=None, gpu_id=0, save_reconstructions=False, use_timestamp=False, experiment_tag=None, random_seed=2022, log_dir='./logs', clean_train_val_data=False, batch_size=1024, num_workers=10, evaluate_retrieval_version=False)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJbXo_3mUYqd",
        "outputId": "70f6cf57-cfc8-469a-99df-4b50590979aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /content/changeit3d\n",
            "../content/changeit3d\n",
            "Directory contents:\n",
            "environment.yml\n",
            "assets\n",
            ".git\n",
            "setup.py\n",
            ".gitmodules\n",
            "changeit3d.egg-info\n",
            "README.md\n",
            "changeit3d\n",
            "logs\n",
            ".gitignore\n",
            "Does the file '/content/drive/Shareddrives/CS766/pretrained_models/data/pretrained/shape_latents/pcae_latent_codes.pkl' exist? True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "print(f\"Current directory: {current_dir}\")\n",
        "new_dir = f'..{current_dir}'\n",
        "print(new_dir)\n",
        "\n",
        "# List all files and directories in the current directory\n",
        "print(\"Directory contents:\")\n",
        "for item in os.listdir(current_dir):\n",
        "    print(item)\n",
        "\n",
        "# Check if the file exists\n",
        "file_path = '../drive/Shareddrives/CS766/pretrained_models/data/pretrained/shape_latents/pcae_latent_codes.pkl'\n",
        "absolute_file_path = os.path.abspath(file_path)\n",
        "file_exists = os.path.isfile(absolute_file_path)\n",
        "print(f\"Does the file '{absolute_file_path}' exist? {file_exists}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6thUo0rs5VAp",
        "outputId": "31de9081-392b-48c2-c93a-f1d3de771db7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Loading pretrained ChangetIt3DNet (C3DNet)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained ChangetIt3DNet (C3DNet)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Latent codes with dimension 256 are loaded.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latent codes with dimension 256 are loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Restricting to class(es) ['chair', 'table', 'lamp']. Total utterances: 217747\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restricting to class(es) ['chair', 'table', 'lamp']. Total utterances: 217747\n",
            "Doing ST ablation decoupling_mag_direction with self contrast True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "INFO:root:The model is variant `decoupling_mag_direction` trained with 0.05 identity penalty and Self-Contrast=True.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model is variant `decoupling_mag_direction` trained with 0.05 identity penalty and Self-Contrast=True.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Loaded at epoch 77.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded at epoch 77.\n"
          ]
        }
      ],
      "source": [
        "logger.info('Loading pretrained ChangetIt3DNet (C3DNet)')\n",
        "df, shape_to_latent_code, shape_latent_dim, vocab = prepare_input_data(args, logger)\n",
        "\n",
        "c3d_net, best_epoch, c3d_args = load_pretrained_changeit3d_net(args.pretrained_changeit3d, shape_latent_dim, vocab)\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:\" + str(args.gpu_id))\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "c3d_net = c3d_net.to(device)\n",
        "logger.info(f'The model is variant `{c3d_args.shape_editor_variant}` trained with {c3d_args.identity_penalty} identity penalty and Self-Contrast={c3d_args.self_contrast}.')\n",
        "logger.info(f'Loaded at epoch {best_epoch}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKyVl-JOucmy"
      },
      "source": [
        "###  Loading the Input Data and PC-AE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKmoQIi_2LN4"
      },
      "outputs": [],
      "source": [
        "from argparse import ArgumentParser\n",
        "import json\n",
        "from changeit3d.models.point_net import PointNet\n",
        "from changeit3d.models.mlp import MLP\n",
        "from changeit3d.models.pointcloud_autoencoder import PointcloudAutoencoder\n",
        "from changeit3d.in_out.basics import load_state_dicts\n",
        "\n",
        "def read_saved_args(config_file, override_or_add_args=None, verbose=False):\n",
        "    \"\"\"\n",
        "    :param config_file: json file containing arguments\n",
        "    :param override_args: dict e.g., {'gpu': '0'} will set the resulting arg.gpu to be 0\n",
        "    :param verbose:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    parser = ArgumentParser()\n",
        "    args = parser.parse_args([])\n",
        "    with open(config_file, 'r') as f_in:\n",
        "        args.__dict__ = json.load(f_in)\n",
        "\n",
        "    if override_or_add_args is not None:\n",
        "        for key, val in override_or_add_args.items():\n",
        "            args.__setattr__(key, val)\n",
        "\n",
        "\n",
        "\n",
        "    return args\n",
        "\n",
        "def describe_pc_ae(args):\n",
        "    # Make an AE.\n",
        "    if args.encoder_net == 'pointnet':\n",
        "        ae_encoder = PointNet(init_feat_dim=3, conv_dims=args.encoder_conv_layers)\n",
        "        encoder_latent_dim = args.encoder_conv_layers[-1]\n",
        "    else:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    if args.decoder_net == 'mlp':\n",
        "        ae_decoder = MLP(in_feat_dims=encoder_latent_dim,\n",
        "                         out_channels=args.decoder_fc_neurons + [args.n_pc_points * 3],\n",
        "                         b_norm=False)\n",
        "\n",
        "    model = PointcloudAutoencoder(ae_encoder, ae_decoder)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def load_pretrained_pc_ae(model_file):\n",
        "    config_file = osp.join(osp.dirname(model_file), 'config.json.txt')\n",
        "    pc_ae_args = read_saved_args(config_file)\n",
        "    pc_ae = describe_pc_ae(pc_ae_args)\n",
        "\n",
        "    # if osp.join(pc_ae_args.log_dir, 'best_model.pt') != osp.abspath(model_file):\n",
        "        # warnings.warn(\"The saved best_model.pt in the corresponding log_dir is not equal to the one requested.\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      best_epoch = load_state_dicts(model_file, model=pc_ae)\n",
        "    else:\n",
        "      best_epoch = load_state_dicts(model_file, model=pc_ae, map_location='cpu')\n",
        "    print(f'Pretrained PC-AE is loaded at epoch {best_epoch}.')\n",
        "    return pc_ae, pc_ae_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mYcXa0Y17aq",
        "outputId": "519d5978-be5c-4fd3-f936-64e56aaa17df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrained PC-AE is loaded at epoch 186.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if args.shape_generator_type == 'pcae':\n",
        "    pc_ae, pc_ae_args = load_pretrained_pc_ae(args.pretrained_shape_generator)\n",
        "    pc_ae = pc_ae.to(device)\n",
        "    pc_ae = pc_ae.eval()\n",
        "elif args.shape_generator_type == 'sgf':\n",
        "    sgf_ae = initialize_and_load_sgf()\n",
        "    sgf_trainer = sgf_ae.trainer\n",
        "    sgf_trainer.cfg.inference.num_points = args.n_sample_points\n",
        "else:\n",
        "    assert False\n",
        "\n",
        "\n",
        "def to_stimulus_func(x):\n",
        "    return shape_to_latent_code[x]\n",
        "\n",
        "split = 'test'\n",
        "ndf = df[df.changeit_split == split].copy()\n",
        "ndf.reset_index(inplace=True, drop=True)\n",
        "\n",
        "if args.sub_sample_dataset is not None:\n",
        "    np.random.seed(args.random_seed)\n",
        "    ndf = ndf.sample(args.sub_sample_dataset)\n",
        "    ndf.reset_index(inplace=True, drop=True)\n",
        "\n",
        "dataset = ShapeTalkCustomShapeDataset(ndf,\n",
        "                                     to_stimulus_func,\n",
        "                                     n_distractors=1,\n",
        "                                     shuffle_items=False)  # important, source (distractor) now is first\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=args.batch_size,\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=args.num_workers,\n",
        "                                         worker_init_fn=lambda _ : np.random.seed(args.random_seed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D6pxI4X4-Rq"
      },
      "source": [
        "## a)  Language Based Evaluation\n",
        "\n",
        "- Run the experiment on varying formats of input data and compare evaluation performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_RwzafB2E4d",
        "outputId": "45df5f8a-771a-415b-d131-986b76dc0cc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "from changeit3d.language.vocabulary import Vocabulary\n",
        "from ast import literal_eval\n",
        "import os\n",
        "\n",
        "language_file_dict = {\n",
        "    'public_version': f'{top_data_dir}/shapetalk/language/shapetalk_preprocessed_public_version_0.csv',\n",
        "    'modified': f'../drive/Shareddrives/CS766/no_shade_utterances_modified.csv'\n",
        "    #'modified': f'{top_data_dir}/shapetalk/language/shapetalk_preprocessed_filtered.csv'\n",
        "    # folder to remove parts\n",
        "    #'modified': f'../../drive/Shareddrives/CS766/shapetalk_preprocessed_filtered_for_shape_removal.csv'\n",
        "    # folder of noisey files\n",
        "    #'modified': f'../../drive/Shareddrives/CS766/custom_noise_dataset_v4.csv'\n",
        "    # should I make a file where the cropped shapes are the source and the OG ones are the target with our own utterances? still need help with token_embedding\n",
        "\n",
        "}\n",
        "\n",
        "output_folder = f\"{top_data_dir}/../generation_results/language/\"\n",
        "\n",
        "def preprocess_and_load_df(args, df_file_name):\n",
        "  cur_df = pd.read_csv(df_file_name)\n",
        "\n",
        "  cur_df.tokens_encoded = cur_df.tokens_encoded.apply(literal_eval)\n",
        "  vocab = Vocabulary.load(args.vocab_file)\n",
        "\n",
        "  if hasattr(args, \"add_shape_glot\") and args.add_shape_glot:\n",
        "      raise NotImplementedError('Not in public version')\n",
        "      cur_df = add_sg_to_snt(cur_df, vocab, args.split_file)\n",
        "\n",
        "  cur_df = cur_df.assign(target=df.target_uid)\n",
        "  cur_df = cur_df.assign(distractor_1=df.source_uid)\n",
        "\n",
        "    # constrain training in language of particular classes\n",
        "  # if len(args.restrict_shape_class) > 0:\n",
        "  #     mask = cur_df.target_object_class.isin(set(args.restrict_shape_class))\n",
        "  #     cur_df = df[mask].copy()\n",
        "  #     cur_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "  #     msg = 'Restricting to class(es) {}. Total utterances: {}'.format(args.restrict_shape_class, len(cur_df))\n",
        "  #     print(msg)\n",
        "\n",
        "  return cur_df\n",
        "\n",
        "for lang_exp_type, exp_file_name in language_file_dict.items():\n",
        "\n",
        "    cur_df = preprocess_and_load_df(args, exp_file_name)\n",
        "    mask = cur_df.target_object_class.isin(set(args.restrict_shape_class))\n",
        "    cur_df = cur_df[mask].copy()\n",
        "    cur_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    msg = 'Restricting to class(es) {}. Total utterances: {}'.format(args.restrict_shape_class, len(cur_df))\n",
        "    cur_dataset = ShapeTalkCustomShapeDataset(cur_df,\n",
        "                                     to_stimulus_func,\n",
        "                                     n_distractors=1,\n",
        "                                     shuffle_items=False)  # important, source (distractor) now is first\n",
        "\n",
        "    cur_dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=args.batch_size,\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=args.num_workers,\n",
        "                                         worker_init_fn=lambda _ : np.random.seed(args.random_seed))\n",
        "\n",
        "\n",
        "    if args.shape_generator_type == 'pcae':\n",
        "      transformation_results = pc_ae_transform_point_clouds(pc_ae,\n",
        "                                                            c3d_net,\n",
        "                                                            cur_dataloader,\n",
        "                                                            stimulus_index=0,\n",
        "                                                            scales=[0, 1],  # use \"0\" to get also the simple reconstruction of the decoder (no edit)\n",
        "                                                            device=device)\n",
        "\n",
        "    elif args.shape_generator_type == 'sgf':\n",
        "      transformation_results = sgf_transform_point_clouds(sgf_trainer,\n",
        "                                                          c3d_net,\n",
        "                                                          cur_dataloader,\n",
        "                                                          stimulus_index=0,\n",
        "                                                          scales=[1],\n",
        "                                                          n_points_per_shape=args.n_sample_points,\n",
        "                                                          batch_size=128,\n",
        "                                                          max_recon_batches=None)\n",
        "\n",
        "\n",
        "    np.save(os.path.join(output_folder, f\"{args.shape_generator_type}_dataset_{lang_exp_type}.npy\"), transformation_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSvEuFLsDmUH"
      },
      "source": [
        "## b) Noisy Point Cloud Evaluation\n",
        "- Pass in the noisy point clouds along with the original language instructions\n",
        "- Compare this with varying levels of noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LiOjWUI4-9dt",
        "outputId": "0d5885e7-5398-4852-dff1-b84633f00ee1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3ee206db3b95>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m def pc_ae_transform_point_clouds(\n\u001b[1;32m      5\u001b[0m     \u001b[0mpc_ae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "@torch.no_grad()\n",
        "def pc_ae_transform_point_clouds(\n",
        "    pc_ae,\n",
        "    direction_finder,\n",
        "    data_loader,\n",
        "    stimulus_index,\n",
        "    scales=[1],\n",
        "    device=\"cuda\",\n",
        "    encode_stimulus = False\n",
        "  ):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        pc_ae:\n",
        "        direction_finder:\n",
        "        data_loader:\n",
        "        stimulus_index: stimulus location in data_loader (e.g., is it the first or the second shape)\n",
        "        scales: use them to multiply the edit_latent before you add it to the original latent, this way you can *manually* boost or attenuate the edit's effect\n",
        "        device:\n",
        "\n",
        "    Returns:\n",
        "        Let's assume that:\n",
        "            1) the input language/shape-dataset concerns the transformation for N shape-language pairs.\n",
        "            2) the latent space is L-dimensional\n",
        "\n",
        "        then,\n",
        "\n",
        "         A dictionary carrying the following items:\n",
        "            'z_codes' -> dict, carrying the updated *final* latent codes. The keys are the input magnitudes. Each value is\n",
        "                an N x L numpy array.\n",
        "            'recons' -> dict, the N decoded/reconstructed point-clouds. The keys are input magnitudes. Each value is\n",
        "                an N x PC-points x 3 numpy array.\n",
        "            'tokens' -> list of lists, the N sentences used to create the transformations\n",
        "            'edit_latents' -> N x L numpy array, the latents corresponding to the edits (before adding them to each input)\n",
        "            'magnitudes' -> N x 1 numpy array, carrying the magnitudes the editing network guessed for each input.\n",
        "    \"\"\"\n",
        "\n",
        "    results = get_transformed_latent_code(pc_ae, direction_finder, data_loader, stimulus_index, scales=scales, device=device, encode_stimulus = encode_stimulus)\n",
        "\n",
        "    pc_ae.eval()\n",
        "    all_recons = defaultdict(list)\n",
        "\n",
        "    for key, val in results['z_codes'].items():\n",
        "        recons = pc_ae.decoder(torch.from_numpy(val).to(device))\n",
        "        recons = recons.view([len(recons), -1, 3]).cpu()\n",
        "        all_recons[key].append(recons)\n",
        "\n",
        "    for key in all_recons:\n",
        "        all_recons[key] = torch.cat(all_recons[key]).numpy()\n",
        "\n",
        "    results['recons'] = all_recons\n",
        "    return results\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_transformed_latent_code(pc_ae, direction_finder, data_loader, stimulus_index, scales=[1], device=\"cuda\", encode_stimulus = False):\n",
        "    \"\"\"  Extract transformation for a given latent code based on LatentDirectionFinder\n",
        "    \"\"\"\n",
        "    direction_finder.eval()\n",
        "\n",
        "    all_z_codes = defaultdict(list)\n",
        "    all_tokens = []\n",
        "    all_edit_latents = []\n",
        "    all_magnitudes = []\n",
        "\n",
        "    # Enumerating the batches of data loader #\n",
        "    for batch in data_loader:\n",
        "        t = batch['tokens'].to(device)\n",
        "\n",
        "        # Should I encode the stimulus function? #\n",
        "        if encode_stimulus:\n",
        "          batch_size, n_distractors, num_points, d = batch['pc_stimulus'].shape\n",
        "          ae_input = batch['pc_stimulus'].view(-1, num_points, d).permute(0, 2, 1).to(device)\n",
        "          batch['stimulus'] = pc_ae.encoder(ae_input.float())\n",
        "          batch['stimulus'] = batch['stimulus'].view(batch_size, n_distractors, -1)\n",
        "\n",
        "        s = batch['stimulus'][:, stimulus_index].to(device)\n",
        "        edit_latent, guessed_mag = direction_finder(t, s)\n",
        "        # print(edit_latent, guessed_mag)\n",
        "\n",
        "        for scale in scales:\n",
        "            if scale == 0:  # no transformation, just return the input/starting latent code\n",
        "                transformed = s\n",
        "            else:\n",
        "                transformed = s + scale * edit_latent\n",
        "\n",
        "            all_z_codes[scale].append(transformed.cpu())\n",
        "        all_edit_latents.append(edit_latent.cpu())\n",
        "        all_magnitudes.append(guessed_mag.cpu())\n",
        "\n",
        "        all_tokens.extend(t.tolist())\n",
        "\n",
        "\n",
        "    all_edit_latents = torch.cat(all_edit_latents).numpy()\n",
        "    all_magnitudes = torch.cat(all_magnitudes).numpy()\n",
        "\n",
        "    for scale in scales:\n",
        "        all_z_codes[scale] = torch.cat(all_z_codes[scale]).numpy()\n",
        "\n",
        "    results = {'z_codes': all_z_codes,\n",
        "               'tokens': all_tokens,\n",
        "               'edit_latents': all_edit_latents,\n",
        "               'magnitudes': all_magnitudes}\n",
        "\n",
        "    return results\n",
        "\n",
        "def load_custom_df(shape_talk_file, args):\n",
        "    df = pd.read_csv(shape_talk_file)\n",
        "    df.tokens_encoded = df.tokens_encoded.apply(literal_eval)\n",
        "    vocab = Vocabulary.load(args.vocab_file)\n",
        "\n",
        "    if hasattr(args, \"add_shape_glot\") and args.add_shape_glot:\n",
        "        raise NotImplementedError('Not in public version')\n",
        "        df = add_sg_to_snt(df, vocab, args.split_file)\n",
        "\n",
        "    df = df.assign(target=df.target_uid)\n",
        "    df = df.assign(distractor_1=df.source_uid)\n",
        "\n",
        "    # if len(args.restrict_shape_class) > 0:\n",
        "        # mask = df.target_object_class.isin(set(args.restrict_shape_class))\n",
        "        # df = df[mask].copy()\n",
        "        # df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4tYpKycCh1o"
      },
      "source": [
        "### Obtain Transformed Points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OR4EeLqd_g5A",
        "outputId": "2257af4f-f3fe-4d41-a689-c4399bee49b5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'top_data_dir' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c5109516a2b0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{top_data_dir}/../generation_results/noisy_point_clouds\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msigma_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0.01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0.02'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0.03'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bottle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'top_data_dir' is not defined"
          ]
        }
      ],
      "source": [
        "output_folder = f\"{top_data_dir}/../generation_results/noisy_point_clouds\"\n",
        "os.makedirs(output_folder, exist_ok = True)\n",
        "\n",
        "sigma_list = ['0.01', '0.02', '0.03']\n",
        "categories = ['mug', 'lamp', 'bottle']\n",
        "pc_data_path = f\"{top_data_dir}/../noise_added_to_point_clouds/\"\n",
        "target_base_dir = f\"{top_data_dir}/shapetalk/point_clouds/scaled_to_align_rendering\"\n",
        "csv_out_path = f\"{top_data_dir}/../noisy_data.csv\"\n",
        "exp_type = \"noisy_pc\"\n",
        "\n",
        "for sigma in sigma_list:\n",
        "  for category in categories:\n",
        "    shape_talk_file = pc_data_path + \"/\"  + category + \"_noise\" + \"Sigma\" + sigma.split('.')[1] + \"_exp1.csv\"\n",
        "    cur_df = load_custom_df(shape_talk_file, args)\n",
        "    print(f\"Running {sigma} on the Category: {category}\")\n",
        "\n",
        "    msg = 'Restricting to class(es) {}. Total utterances: {}'.format(args.restrict_shape_class, len(cur_df))\n",
        "    cur_dataset = ShapeTalkCustomShapeDataset(\n",
        "                                      cur_df,\n",
        "                                      base_data_dir=pc_data_path,\n",
        "                                      target_base_dir=target_base_dir,\n",
        "                                      to_stimulus_func=None,\n",
        "                                      n_distractors=1,\n",
        "                                      shuffle_items=False)  # important, source (distractor) now is first\n",
        "\n",
        "    cur_dataloader = torch.utils.data.DataLoader(dataset=cur_dataset,\n",
        "                                            batch_size=8,\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=1,\n",
        "                                            worker_init_fn=lambda _ : np.random.seed(args.random_seed))\n",
        "\n",
        "\n",
        "    cur_dataset.df.to_csv(csv_out_path)\n",
        "    full_df = cur_dataset.df\n",
        "    if args.shape_generator_type == 'pcae':\n",
        "        transformation_results = pc_ae_transform_point_clouds(pc_ae,\n",
        "                                                              c3d_net,\n",
        "                                                              cur_dataloader,\n",
        "                                                              stimulus_index=0,\n",
        "                                                              scales=[0, 1],  # use \"0\" to get also the simple reconstruction of the decoder (no edit)\n",
        "                                                              device=device,\n",
        "                                                              encode_stimulus=True)\n",
        "\n",
        "    elif args.shape_generator_type == 'sgf':\n",
        "        transformation_results = sgf_transform_point_clouds(sgf_trainer,\n",
        "                                                            c3d_net,\n",
        "                                                            cur_dataloader,\n",
        "                                                            stimulus_index=0,\n",
        "                                                            scales=[1],\n",
        "                                                            n_points_per_shape=args.n_sample_points,\n",
        "                                                            batch_size=128,\n",
        "                                                            max_recon_batches=None)\n",
        "\n",
        "    np.save(os.path.join(output_folder, f\"{args.shape_generator_type}_dataset_{exp_type}_{sigma}_{category}.npy\"), transformation_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrw9iAjRIQwU"
      },
      "source": [
        "### c) Segmented Point Clouds:\n",
        "- Show that using segmentation of parts in the target along with an input which is used for the rest of the experiments\n",
        "- Using the language instruction to segment the point clouds (Missing arms)/Legs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x0EQkI5Aj5P"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "YP0cVa0ZJFzH",
        "outputId": "38922947-2f43-4dd2-8b89-bbf686137906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Stimulus None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-106-a54072ea9d87>\", line 78, in __getitem__\n    test_pc_path = self.base_data_dir + \"/\" + item_class + \"/\" + item_code + \".npz\"\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'str'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-7e1dcd5943e8>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using Stimulus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_stimulus_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-106-a54072ea9d87>\", line 78, in __getitem__\n    test_pc_path = self.base_data_dir + \"/\" + item_class + \"/\" + item_code + \".npz\"\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'str'\n"
          ]
        }
      ],
      "source": [
        "output_folder = f\"{top_data_dir}/../generation_results/noisy_point_clouds\"\n",
        "os.makedirs(output_folder, exist_ok = True)\n",
        "\n",
        "sigma_list = ['0.01', '0.02', '0.03']\n",
        "categories = ['vase', 'mug', 'lamp', 'bottle']\n",
        "pc_data_path = f\"{top_data_dir}/../noise_added_to_point_clouds/\"\n",
        "target_base_dir = f\"{top_data_dir}/shapetalk/point_clouds/scaled_to_align_rendering\"\n",
        "csv_out_path = f\"{top_data_dir}/../noisy_data.csv\"\n",
        "exp_type = \"noisy_pc\"\n",
        "\n",
        "shape_talk_file = pc_data_path + \"/\"  + category + \"_noise\" + \"Sigma\" + sigma.split('.')[1] + \"_exp1.csv\"\n",
        "cur_df = load_custom_df(shape_talk_file, args)\n",
        "print(f\"Running {sigma} on the Category: {category}\")\n",
        "\n",
        "cur_dataset = ShapeTalkCustomShapeDataset(\n",
        "                                  cur_df,\n",
        "                                  base_data_dir=pc_data_path,\n",
        "                                  target_base_dir=target_base_dir,\n",
        "                                  to_stimulus_func=None,\n",
        "                                  n_distractors=1,\n",
        "                                  shuffle_items=False)  # important, source (distractor) now is first\n",
        "\n",
        "cur_dataloader = torch.utils.data.DataLoader(dataset=cur_dataset,\n",
        "                                            batch_size=8,\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=1,\n",
        "                                            worker_init_fn=lambda _ : np.random.seed(args.random_seed))\n",
        "\n",
        "    cur_dataset.df.to_csv(csv_out_path)\n",
        "    full_df = cur_dataset.df\n",
        "    # Point Cloud Auto-Encoder #\n",
        "    if args.shape_generator_type == 'pcae':\n",
        "        transformation_results = pc_ae_transform_point_clouds(pc_ae,\n",
        "                                                              c3d_net,\n",
        "                                                              cur_dataloader,\n",
        "                                                              stimulus_index=0,\n",
        "                                                              scales=[0, 1],  # use \"0\" to get also the simple reconstruction of the decoder (no edit)\n",
        "                                                              device=device,\n",
        "                                                              encode_stimulus=True)\n",
        "    # If the shape generator is SGF #\n",
        "    elif args.shape_generator_type == 'sgf':\n",
        "        transformation_results = sgf_transform_point_clouds(sgf_trainer,\n",
        "                                                            c3d_net,\n",
        "                                                            cur_dataloader,\n",
        "                                                            stimulus_index=0,\n",
        "                                                            scales=[1],\n",
        "                                                            n_points_per_shape=args.n_sample_points,\n",
        "                                                            batch_size=128,\n",
        "                                                            max_recon_batches=None)\n",
        "\n",
        "    np.save(os.path.join(output_folder, f\"{args.shape_generator_type}_dataset_{exp_type}_{sigma}_{category}.npy\"), transformation_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwVuBjvRASNG",
        "outputId": "11faaae0-51e0-4d40-9860-4cdb392d0b44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['tokens', 'label', 'index', 'stimulus'])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx2-nMAjAfY7"
      },
      "outputs": [],
      "source": [
        "cur_dataset.shape_to_latent_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B9wFcZ8EIpg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSFD7my8EIEk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNPkjXVDFAG2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
